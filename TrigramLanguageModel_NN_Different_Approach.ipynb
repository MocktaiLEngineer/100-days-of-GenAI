{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MocktaiLEngineer/100-days-of-GenAI/blob/main/TrigramLanguageModel_NN_Different_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "pSOlVjuGa9Qv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krgQ4l9vYEd9",
        "outputId": "32e210ed-716c-4693-81a9-292924ae56be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-25 11:28:43--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-03-25 11:28:43 (13.9 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the names.txt file\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt','r').read().splitlines()"
      ],
      "metadata": {
        "id": "0Lr-NlWVYbII"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN = '.'\n",
        "vocab = [TOKEN] + sorted(list(set(''.join(words)))) "
      ],
      "metadata": {
        "id": "rmS__lj6Zeik"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(vocab)"
      ],
      "metadata": {
        "id": "FIBSlO3KgcES"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int = {char:i for i,char in enumerate(vocab)}\n",
        "int_to_char = {i:char for char,i in char_to_int.items()}"
      ],
      "metadata": {
        "id": "xXYltqmHZrYT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset of bigrams (x,y)\n",
        "\n",
        "X,Y = [],[]\n",
        "\n",
        "for word in words:\n",
        "    word = [TOKEN] + list(word) + [TOKEN]\n",
        "    for ch1,ch2,ch3 in zip(word,word[1:],word[2:]):\n",
        "        ix1 = char_to_int[ch1]\n",
        "        ix2 = char_to_int[ch2]\n",
        "        ix3 = char_to_int[ch3]\n",
        "        X.append([ix1,ix2])\n",
        "        Y.append(ix3)\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "\n",
        "print(X,Y)\n",
        "\n",
        "# Initialising the network\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "W = torch.randn((n ,n), requires_grad = True, generator=g)\n",
        "num = X.shape[0]"
      ],
      "metadata": {
        "id": "7XIzsjrzYQDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd481b8-d19d-48f8-a13b-74a97794402a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  5],\n",
            "        [ 5, 13],\n",
            "        [13, 13],\n",
            "        ...,\n",
            "        [26, 25],\n",
            "        [25, 26],\n",
            "        [26, 24]]) tensor([13, 13,  1,  ..., 26, 24,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200):\n",
        "    # Forward pass\n",
        "    xenc = F.one_hot(X, num_classes = n).float()\n",
        "    \n",
        "    xenc_sum = xenc.sum(dim = 1, keepdim = False)\n",
        "\n",
        "    logits = xenc_sum @ W #Log counts\n",
        "    counts = logits.exp()\n",
        "    probs = counts / torch.sum(counts, dim = 1, keepdim = True)\n",
        "\n",
        "    loss = -probs[torch.arange(num), Y].log().mean() \n",
        "\n",
        "    # Backward pass\n",
        "    W.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    W.data += -35 * W.grad\n",
        "\n",
        "    print(f\"Iteration:{i} | {loss=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nkimpiPg8WwJ",
        "outputId": "54e15ec6-f1a9-4d36-bd9e-8ad6fc9534e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:0 | loss=tensor(2.4079, grad_fn=<NegBackward0>)\n",
            "Iteration:1 | loss=tensor(2.4078, grad_fn=<NegBackward0>)\n",
            "Iteration:2 | loss=tensor(2.4077, grad_fn=<NegBackward0>)\n",
            "Iteration:3 | loss=tensor(2.4077, grad_fn=<NegBackward0>)\n",
            "Iteration:4 | loss=tensor(2.4076, grad_fn=<NegBackward0>)\n",
            "Iteration:5 | loss=tensor(2.4076, grad_fn=<NegBackward0>)\n",
            "Iteration:6 | loss=tensor(2.4075, grad_fn=<NegBackward0>)\n",
            "Iteration:7 | loss=tensor(2.4075, grad_fn=<NegBackward0>)\n",
            "Iteration:8 | loss=tensor(2.4074, grad_fn=<NegBackward0>)\n",
            "Iteration:9 | loss=tensor(2.4074, grad_fn=<NegBackward0>)\n",
            "Iteration:10 | loss=tensor(2.4073, grad_fn=<NegBackward0>)\n",
            "Iteration:11 | loss=tensor(2.4072, grad_fn=<NegBackward0>)\n",
            "Iteration:12 | loss=tensor(2.4072, grad_fn=<NegBackward0>)\n",
            "Iteration:13 | loss=tensor(2.4071, grad_fn=<NegBackward0>)\n",
            "Iteration:14 | loss=tensor(2.4071, grad_fn=<NegBackward0>)\n",
            "Iteration:15 | loss=tensor(2.4070, grad_fn=<NegBackward0>)\n",
            "Iteration:16 | loss=tensor(2.4070, grad_fn=<NegBackward0>)\n",
            "Iteration:17 | loss=tensor(2.4069, grad_fn=<NegBackward0>)\n",
            "Iteration:18 | loss=tensor(2.4069, grad_fn=<NegBackward0>)\n",
            "Iteration:19 | loss=tensor(2.4068, grad_fn=<NegBackward0>)\n",
            "Iteration:20 | loss=tensor(2.4068, grad_fn=<NegBackward0>)\n",
            "Iteration:21 | loss=tensor(2.4068, grad_fn=<NegBackward0>)\n",
            "Iteration:22 | loss=tensor(2.4067, grad_fn=<NegBackward0>)\n",
            "Iteration:23 | loss=tensor(2.4067, grad_fn=<NegBackward0>)\n",
            "Iteration:24 | loss=tensor(2.4066, grad_fn=<NegBackward0>)\n",
            "Iteration:25 | loss=tensor(2.4066, grad_fn=<NegBackward0>)\n",
            "Iteration:26 | loss=tensor(2.4065, grad_fn=<NegBackward0>)\n",
            "Iteration:27 | loss=tensor(2.4065, grad_fn=<NegBackward0>)\n",
            "Iteration:28 | loss=tensor(2.4064, grad_fn=<NegBackward0>)\n",
            "Iteration:29 | loss=tensor(2.4064, grad_fn=<NegBackward0>)\n",
            "Iteration:30 | loss=tensor(2.4063, grad_fn=<NegBackward0>)\n",
            "Iteration:31 | loss=tensor(2.4063, grad_fn=<NegBackward0>)\n",
            "Iteration:32 | loss=tensor(2.4063, grad_fn=<NegBackward0>)\n",
            "Iteration:33 | loss=tensor(2.4062, grad_fn=<NegBackward0>)\n",
            "Iteration:34 | loss=tensor(2.4062, grad_fn=<NegBackward0>)\n",
            "Iteration:35 | loss=tensor(2.4061, grad_fn=<NegBackward0>)\n",
            "Iteration:36 | loss=tensor(2.4061, grad_fn=<NegBackward0>)\n",
            "Iteration:37 | loss=tensor(2.4061, grad_fn=<NegBackward0>)\n",
            "Iteration:38 | loss=tensor(2.4060, grad_fn=<NegBackward0>)\n",
            "Iteration:39 | loss=tensor(2.4060, grad_fn=<NegBackward0>)\n",
            "Iteration:40 | loss=tensor(2.4059, grad_fn=<NegBackward0>)\n",
            "Iteration:41 | loss=tensor(2.4059, grad_fn=<NegBackward0>)\n",
            "Iteration:42 | loss=tensor(2.4059, grad_fn=<NegBackward0>)\n",
            "Iteration:43 | loss=tensor(2.4058, grad_fn=<NegBackward0>)\n",
            "Iteration:44 | loss=tensor(2.4058, grad_fn=<NegBackward0>)\n",
            "Iteration:45 | loss=tensor(2.4058, grad_fn=<NegBackward0>)\n",
            "Iteration:46 | loss=tensor(2.4057, grad_fn=<NegBackward0>)\n",
            "Iteration:47 | loss=tensor(2.4057, grad_fn=<NegBackward0>)\n",
            "Iteration:48 | loss=tensor(2.4057, grad_fn=<NegBackward0>)\n",
            "Iteration:49 | loss=tensor(2.4056, grad_fn=<NegBackward0>)\n",
            "Iteration:50 | loss=tensor(2.4056, grad_fn=<NegBackward0>)\n",
            "Iteration:51 | loss=tensor(2.4056, grad_fn=<NegBackward0>)\n",
            "Iteration:52 | loss=tensor(2.4055, grad_fn=<NegBackward0>)\n",
            "Iteration:53 | loss=tensor(2.4055, grad_fn=<NegBackward0>)\n",
            "Iteration:54 | loss=tensor(2.4055, grad_fn=<NegBackward0>)\n",
            "Iteration:55 | loss=tensor(2.4054, grad_fn=<NegBackward0>)\n",
            "Iteration:56 | loss=tensor(2.4054, grad_fn=<NegBackward0>)\n",
            "Iteration:57 | loss=tensor(2.4054, grad_fn=<NegBackward0>)\n",
            "Iteration:58 | loss=tensor(2.4053, grad_fn=<NegBackward0>)\n",
            "Iteration:59 | loss=tensor(2.4053, grad_fn=<NegBackward0>)\n",
            "Iteration:60 | loss=tensor(2.4053, grad_fn=<NegBackward0>)\n",
            "Iteration:61 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:62 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:63 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:64 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:65 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:66 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:67 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:68 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:69 | loss=tensor(2.4052, grad_fn=<NegBackward0>)\n",
            "Iteration:70 | loss=tensor(2.4053, grad_fn=<NegBackward0>)\n",
            "Iteration:71 | loss=tensor(2.4054, grad_fn=<NegBackward0>)\n",
            "Iteration:72 | loss=tensor(2.4055, grad_fn=<NegBackward0>)\n",
            "Iteration:73 | loss=tensor(2.4058, grad_fn=<NegBackward0>)\n",
            "Iteration:74 | loss=tensor(2.4060, grad_fn=<NegBackward0>)\n",
            "Iteration:75 | loss=tensor(2.4066, grad_fn=<NegBackward0>)\n",
            "Iteration:76 | loss=tensor(2.4071, grad_fn=<NegBackward0>)\n",
            "Iteration:77 | loss=tensor(2.4082, grad_fn=<NegBackward0>)\n",
            "Iteration:78 | loss=tensor(2.4089, grad_fn=<NegBackward0>)\n",
            "Iteration:79 | loss=tensor(2.4111, grad_fn=<NegBackward0>)\n",
            "Iteration:80 | loss=tensor(2.4119, grad_fn=<NegBackward0>)\n",
            "Iteration:81 | loss=tensor(2.4157, grad_fn=<NegBackward0>)\n",
            "Iteration:82 | loss=tensor(2.4157, grad_fn=<NegBackward0>)\n",
            "Iteration:83 | loss=tensor(2.4217, grad_fn=<NegBackward0>)\n",
            "Iteration:84 | loss=tensor(2.4197, grad_fn=<NegBackward0>)\n",
            "Iteration:85 | loss=tensor(2.4275, grad_fn=<NegBackward0>)\n",
            "Iteration:86 | loss=tensor(2.4226, grad_fn=<NegBackward0>)\n",
            "Iteration:87 | loss=tensor(2.4316, grad_fn=<NegBackward0>)\n",
            "Iteration:88 | loss=tensor(2.4243, grad_fn=<NegBackward0>)\n",
            "Iteration:89 | loss=tensor(2.4338, grad_fn=<NegBackward0>)\n",
            "Iteration:90 | loss=tensor(2.4250, grad_fn=<NegBackward0>)\n",
            "Iteration:91 | loss=tensor(2.4347, grad_fn=<NegBackward0>)\n",
            "Iteration:92 | loss=tensor(2.4252, grad_fn=<NegBackward0>)\n",
            "Iteration:93 | loss=tensor(2.4350, grad_fn=<NegBackward0>)\n",
            "Iteration:94 | loss=tensor(2.4253, grad_fn=<NegBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cb142abaa994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxenc_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxenc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxenc_sum\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m \u001b[0;31m#Log counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's sample and generate\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "\n",
        "for i in range(10):\n",
        "  name = []\n",
        "  \n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix1,ix2]), num_classes = n).float()\n",
        "    \n",
        "    xenc_sum = xenc.sum(dim = 0, keepdim = False)\n",
        "    \n",
        "    logits = xenc_sum @ W #Log counts\n",
        "\n",
        "\n",
        "    counts = logits.exp()\n",
        "    probs = counts / torch.sum(counts, dim = 0, keepdim = True)\n",
        "    ix2 = torch.multinomial(probs, num_samples = 1, replacement = True, generator = g).item()\n",
        "    name.append(int_to_char[ix2])\n",
        "\n",
        "    ix1 = ix2\n",
        "\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STG63E8d8GXX",
        "outputId": "532d4075-096b-4655-b0e8-548139879bf5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mon.\n",
            "avo.\n",
            "linetorovigramnanialucea.\n",
            "milylny.\n",
            "rih.\n",
            "odenanaleigerialelinelylenaigushl.\n",
            "adat.\n",
            "adelyn.\n",
            "anananleridemign.\n",
            "ah.\n"
          ]
        }
      ]
    }
  ]
}